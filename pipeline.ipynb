{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "## Setting up\n",
    "### set module paths and data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "minian_path = \".\"\n",
    "dpath = \"./demo_movies/\"\n",
    "meta_dict={'session_id': -1, 'session': -2, 'animal': -3}\n",
    "chunks = {'frame': 50, 'height': 80, 'width': 80, 'unit_id':50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(minian_path)\n",
    "import gc\n",
    "import psutil\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import paramnb\n",
    "import matplotlib.pyplot as plt\n",
    "import bokeh.plotting as bpl\n",
    "import dask.array as da\n",
    "import pandas as pd\n",
    "import dask\n",
    "import datashader as ds\n",
    "from holoviews.operation.datashader import datashade, regrid, dynspread\n",
    "from datashader.colors import Sets1to3\n",
    "from dask.diagnostics import ProgressBar\n",
    "from IPython.core.display import display, HTML\n",
    "from dask.distributed import Client, progress\n",
    "from minian.utilities import load_videos, varray_to_tif, save_cnmf, save_movies, scale_varr, save_variable\n",
    "from minian.preprocessing import remove_brightspot, gradient_norm, denoise, remove_background\n",
    "from minian.motion_correction import estimate_shift_fft, apply_shifts, interpolate_frame\n",
    "from minian.initialization import seeds_init, gmm_refine, pnr_refine, intensity_refine, ks_refine, seeds_merge, initialize\n",
    "from minian.cnmf import get_noise_fft, get_noise_welch, update_spatial, update_temporal, unit_merge\n",
    "from minian.visualization import VArrayViewer, MCViewer, CNMFViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### module initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dpath = os.path.abspath(dpath)\n",
    "hv.notebook_extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "### loading videos and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "varr = load_videos(dpath)\n",
    "varr_ref = scale_varr(varr.astype(float), (0,1), inplace=False).chunk(dict(frame=chunks['frame'], height=chunks['height'], width=chunks['width']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bright spots removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    varr_ref = remove_brightspot(varr_ref).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with ProgressBar():\n",
    "    varr_gradient = gradient_norm(varr_ref.isel(frame=0)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa = varr_gradient.quantile(0.9).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anisotropic diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(scheduler='single-threaded'):\n",
    "    varr_ref_anisotropic = denoise(varr_ref, 'anisotropic', niter=10, kappa=kappa, gamma=0.25, option=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref_tophat = remove_background(varr_ref_anisotropic, method='tophat', wnd=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_ref = scale_varr(varr_ref_tophat, (0, 1)).persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=70\n",
    "vaviewer = VArrayViewer([varr, varr_ref], framerate=5)\n",
    "display(vaviewer.widgets)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## motion correction\n",
    "### estimate shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(scheduler='single-threaded'):\n",
    "    shifts, corr, mask = estimate_shift_fft(varr_ref, z_thres=None, on='perframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_mc, shifts_final = apply_shifts(varr_ref.load(), shifts, aggregate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "varr_mc_int = interpolate_frame(varr_mc, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of motion-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=70 fps=5\n",
    "vaviewer = VArrayViewer([varr_ref, varr_mc_int], framerate=5)\n",
    "display(vaviewer.widgets)\n",
    "vaviewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization of shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=100\n",
    "%%opts Curve [width=1500, tools=['hover']]\n",
    "hv.NdOverlay(dict(width=hv.Curve(shifts_final.sel(shift_dim='width')), height=hv.Curve(shifts_final.sel(shift_dim='height'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save result as DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(varr_mc_int.rename('Y'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds = seeds_init(varr_mc_int, method='rolling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_gmm = gmm_refine(varr_mc_int, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_pnr = pnr_refine(varr_mc_int, seeds_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_int = intensity_refine(varr_mc_int, seeds_pnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_ks = ks_refine(varr_mc_int, seeds_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seeds_mrg = seeds_merge(varr_mc_int, seeds_ks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "A, C, b, f = initialize(varr_mc_int, seeds_mrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(A.rename('A_init').rename(unit_id='unit_id_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(C.rename('C_init').rename(unit_id='unit_id_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(b.rename('b_init'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(f.rename('f_init'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNMF\n",
    "### loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian = xr.open_dataset(os.path.join(dpath, 'minian.nc'), chunks=dict(height=chunks['height'], width=chunks['width'], unit_id_init=chunks['unit_id'], frame=chunks['frame']), autoclose=True)\n",
    "Y = minian['Y']\n",
    "A_init = minian['A_init'].rename(unit_id_init='unit_id')\n",
    "C_init = minian['C_init'].rename(unit_id_init='unit_id')\n",
    "b_init = minian['b_init']\n",
    "f_init = minian['f_init']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate spatial noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sn_spatial, psd = get_noise_fft(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first spatial update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(scheduler='processes'):\n",
    "    A_spatial, b_spatial, C_spatial, f_spatial = update_spatial(Y, A_init, b_init, C_init, f_init, sn_spatial, sparse_penal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regrid(hv.Image(A_init.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))\\\n",
    "+ regrid(hv.Image(A_spatial.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(scheduler='threads'):\n",
    "    YrA, C_temporal, S_temporal, B_temporal, C0_temporal, g_temporal = update_temporal(Y, A_spatial, b_spatial, C_spatial, f_spatial, sn_spatial, noise_freq=0.05, sparse_penal=1, use_spatial=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "def construct_G(g, T):\n",
    "    cur_c, cur_r = np.zeros(T), np.zeros(T)\n",
    "    cur_c[0] = 1\n",
    "    cur_r[0] = 1\n",
    "    cur_c[1:len(g) + 1] = -g\n",
    "    return linalg.toeplitz(cur_c, cur_r)\n",
    "\n",
    "def normalize(a): return np.interp(a, (a.min(), a.max()), (0, +1))\n",
    "\n",
    "def convolve_G(s, g):\n",
    "    G = construct_G(g, len(s))\n",
    "    try:\n",
    "        c = linalg.inv(G).dot(s)\n",
    "    except LinAlgError:\n",
    "        c = s.copy()\n",
    "    return c\n",
    "\n",
    "def construct_pulse_response(g):\n",
    "    s = np.zeros(500)\n",
    "    s[10] = 1\n",
    "    c = convolve_G(s, g)\n",
    "    return s, c\n",
    "\n",
    "def visualize_temporal_update(YA, C, S, g):\n",
    "    C_norm = xr.apply_ufunc(normalize, C, input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[C.dtype])\n",
    "    S_norm = xr.apply_ufunc(normalize, S, input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[S.dtype])\n",
    "    YA_norm = xr.apply_ufunc(normalize, YA.compute(), input_core_dims=[['frame']], output_core_dims=[['frame']], vectorize=True, dask='parallelized', output_dtypes=[YA.dtype])\n",
    "    s_pul, c_pul = xr.apply_ufunc(construct_pulse_response, g.compute(), input_core_dims=[['lag']], output_core_dims=[['frame'], ['frame']], vectorize=True, output_sizes=dict(t=500))\n",
    "    s_pul = s_pul.assign_coords(frame=np.arange(500))\n",
    "    c_pul = c_pul.assign_coords(frame=np.arange(500))\n",
    "    hv_s_pul = hv.Dataset(s_pul.rename('s_pul'), kdims=['unit_id', 'frame'])\n",
    "    hv_c_pul = hv.Dataset(c_pul.rename('c_pul'), kdims=['unit_id', 'frame'])\n",
    "    with ProgressBar():\n",
    "        hv_C = hv.Dataset(C_norm.compute().rename('Calcium trace'), kdims=['unit_id', 'frame'])\n",
    "        hv_S = hv.Dataset(S_norm.compute().rename('Spike'), kdims=['unit_id', 'frame'])\n",
    "        hv_YA = hv.Dataset(YA_norm.compute().rename('Raw'), kdims=['unit_id', 'frame'])\n",
    "    hv_obj = hv_C.to(hv.Curve, kdims=['frame'], label='Calcium trace')\\\n",
    "    * hv_S.to(hv.Curve, kdims=['frame'], label='Spike')\\\n",
    "    * hv_YA.to(hv.Curve, kdims=['frame'], label='YA')\\\n",
    "    + hv_c_pul.to(hv.Curve, kdims=['frame'], label='Simulated Calcium')\\\n",
    "    * hv_s_pul.to(hv.Curve, kdims=['frame'], label='Simultaed Spike')\n",
    "    return hv_obj.cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=1200] {+framewise}\n",
    "visualize_temporal_update(YrA, C_temporal, S_temporal, g_temporal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_mrg, C_mrg = unit_merge(A_spatial, C_temporal, thres_corr=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=80\n",
    "regrid(hv.Dataset(A_spatial.rename('A_spatial'), kdims=['height', 'width', 'unit_id']).to(hv.Image, kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))\\\n",
    "+ regrid(hv.Dataset(A_mrg.rename('A_merged'), kdims=['height', 'width', 'unit_id']).to(hv.Image, kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second spatial update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with dask.config.set(scheduler='processes'):\n",
    "    A_spatial_it2, b_spatial_it2, C_spatial_it2, f_spatial_it2 = update_spatial(Y, A_mrg, b_spatial, C_mrg, f_spatial, sn_spatial, sparse_penal=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrid(hv.Image(A_spatial.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))\\\n",
    "+ regrid(hv.Image(A_spatial_it2.sum('unit_id'), kdims=['width', 'height'])).opts(plot=dict(height=480, width=752))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### second temporal update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "YrA, C_temporal_it2, S_temporal_it2, B_temporal_it2, C0_temporal_it2, g_temporal_it2 = update_temporal(Y, A_spatial_it2, b_spatial_it2, C_spatial_it2, f_spatial_it2, sn_spatial, noise_freq=0.05, sparse_penal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts Curve [width=1200] {+framewise}\n",
    "visualize_temporal_update(YrA, C_temporal_it2, S_temporal_it2, g_temporal_it2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save_variable(A_spatial_it2.rename('A'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(C_temporal_it2.rename('C'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(S_temporal_it2.rename('S'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(g_temporal_it2.rename('g'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(b_spatial_it2.rename('b'), dpath, 'minian', meta_dict=meta_dict)\n",
    "save_variable(f_spatial_it2.rename('f'), dpath, 'minian', meta_dict=meta_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian = xr.open_dataset(os.path.join(dpath, 'minian.nc'), chunks=dict(height=chunks['height'], width=chunks['width'], unit_id=chunks['unit_id'], frame=chunks['frame']), autoclose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnmfviewer = CNMFViewer(minian, minian['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cnmfviewer.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "pipeline.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
