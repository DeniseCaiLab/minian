{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify Directory and File Information\n",
    "\n",
    "`minian_path` is the directory containing minian, `dpath` is the directory containing the videos to be cross-registered and their corresponding minian output data (each pair of videos+output should be in a unique folder), `f_pattern` is a regular expression identifying the naming pattern of minian output folders with a regex expression (e.g. `'minian$'`, or `r'minian\\.[0-9]+$'` if data is batch processed and has a timestamp), and `id_dims` should be a list containing metadata identifiers used when analyzing the individual sessions (e.g. `['session','animal']`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = \".\"\n",
    "dpath = \"./demo_movies\"\n",
    "f_pattern = r'minian\\.[0-9]+$' \n",
    "id_dims = ['animal','session']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Paramaters\n",
    "`param_t_dist` defines the maximal distance between cell centroids (in pixel units) on different sessions to consider them as the same cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_t_dist = 5\n",
    "output_size = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.append(minian_path)\n",
    "import itertools as itt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from minian.cross_registration import (estimate_shifts, calculate_centroids,\n",
    "                                       calculate_centroid_distance, calculate_mapping,\n",
    "                                       group_by_session, resolve_mapping, fill_mapping)\n",
    "from minian.motion_correction import apply_shifts\n",
    "from minian.utilities import open_minian, open_minian_mf\n",
    "from minian.visualization import AlignViewer\n",
    "hv.notebook_extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allign Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load minian files as pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_df = open_minian_mf(\n",
    "    dpath, id_dims, result_format='pandas', \n",
    "    backend='zarr', pattern=f_pattern, \n",
    "    chunks=dict(frame='auto', height='auto', width='auto', unit_id='auto'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate initial allignment and modify as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "shiftds = estimate_shifts(minian_df, template='mean', pct_thres=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hv.output(size=output_size)\n",
    "alignviewer = AlignViewer(shiftds, pct_thres=99.99)\n",
    "alignviewer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### apply shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shiftds = alignviewer.shiftds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Centroid Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view overlap of field of view across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian = open_minian_mf(\n",
    "    dpath, id_dims, result_format='xarray', backend='zarr',\n",
    "    pattern=f_pattern, chunks=dict(height='auto', width='auto', frame='auto', unit_id='auto'))\n",
    "A_shifted = apply_shifts(minian['A'].chunk(dict(height=-1, width=-1, unit_id='auto')), shiftds['shifts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [height=480, width=752, colorbar=True] (cmap='Viridis')\n",
    "hv.output(size=output_size)\n",
    "\n",
    "window = shiftds['temps_shifted'].isnull().sum('session')\n",
    "window, temps_sh = xr.broadcast(window, shiftds['temps_shifted'])\n",
    "hv_wnd = hv.Dataset(window, kdims=list(window.dims)).to(hv.Image, ['width', 'height'])\n",
    "hv_temps = hv.Dataset(temps_sh, kdims=list(temps_sh.dims)).to(hv.Image, ['width', 'height'])\n",
    "regrid(hv_wnd, aggregator='max').relabel(\"Window\") + regrid(hv_temps).relabel(\"Shifted Templates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and view cell centroids across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_window(wnd):\n",
    "    return wnd == wnd.min()\n",
    "window = xr.apply_ufunc(\n",
    "    set_window,\n",
    "    window,\n",
    "    input_core_dims=[['height', 'width']],\n",
    "    output_core_dims=[['height', 'width']],\n",
    "    vectorize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cents = calculate_centroids(A_shifted, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Points [height=480, width=752] {+axiswise +framewise}\n",
    "hv.output(size=output_size)\n",
    "\n",
    "cents_hv = hv.Dataset(cents, kdims=['height', 'width', 'unit_id', 'animal', 'session'])\n",
    "cents_hv.to(hv.Points, kdims=['width', 'height']).overlay('unit_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate centroid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dist = calculate_centroid_distance(cents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Overlap Across Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold overlap based upon centroid distance and generate overlap mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ft = dist[dist['variable', 'distance'] < param_t_dist]\n",
    "dist_ft = group_by_session(dist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mappings = calculate_mapping(dist_ft)\n",
    "mappings_meta = resolve_mapping(mappings)\n",
    "mappings_meta_fill = fill_mapping(mappings_meta, cents)\n",
    "mappings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save overlap mappings to pkl and csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_meta_fill.to_pickle(os.path.join(dpath, \"mappings_meta_fill.pkl\"))\n",
    "mappings_meta_fill.to_csv(os.path.join(dpath, \"mappings_meta_fill.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Overlap Across Any 2 Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define session names to be compared in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = ['Day1', 'Day2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### view overlapping/non-overlapping cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_by_session(sessions, mappings):\n",
    "    mappings_ma = mappings[mappings['session'][sessions].notnull().all(axis='columns')]\n",
    "    mappings_non = mappings[\n",
    "        mappings['meta', 'group'].isnull()\n",
    "        & mappings['session'][sess].notnull().any(axis='columns')]\n",
    "    return mappings_ma, mappings_non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dim = ['animal']\n",
    "mappings_match, mappings_nonmatch = subset_by_session(sess, mappings_meta_fill)\n",
    "A_dict = dict()\n",
    "cent_dict = dict()\n",
    "for cur_ss in sess:\n",
    "    cur_uid_ma = mappings_match[[('meta', d) for d in group_dim] + [('session', cur_ss)]]\n",
    "    cur_uid_nm = mappings_nonmatch[[('meta', d) for d in group_dim] + [('session', cur_ss)]].dropna()\n",
    "    cur_uid_ma.columns = cur_uid_ma.columns.droplevel()\n",
    "    cur_uid_nm.columns = cur_uid_nm.columns.droplevel()\n",
    "    cur_uid_ma = cur_uid_ma.rename(columns={cur_ss:'unit_id'})\n",
    "    cur_uid_nm = cur_uid_nm.rename(columns={cur_ss:'unit_id'})\n",
    "    cur_uid_ma['session'] = cur_ss\n",
    "    cur_uid_nm['session'] = cur_ss\n",
    "    cur_cents_ma = cur_uid_ma.merge(cents)\n",
    "    cur_cents_nm = cur_uid_nm.merge(cents)\n",
    "    A_ma_dict = dict()\n",
    "    A_nm_dict = dict()\n",
    "    for igrp, grp_ma in cur_uid_ma.groupby(group_dim + ['session']):\n",
    "        cur_keys = {d: k for d, k in zip(group_dim + ['session'], igrp)}\n",
    "        A_sub = A_shifted.sel(**cur_keys)\n",
    "        A_ma = A_sub.sel(unit_id=grp_ma['unit_id'].values)\n",
    "        grp_nm = cur_uid_nm.query(\" and \".join([\"==\".join((d, \"'{}'\".format(k))) for d, k in cur_keys.items()]))\n",
    "        A_nm = A_sub.sel(unit_id=grp_nm['unit_id'].values)\n",
    "        A_ma_dict[igrp] = hv.Image(A_ma.sum('unit_id').compute(), kdims=['width', 'height'])\n",
    "        A_nm_dict[igrp] = hv.Image(A_nm.sum('unit_id').compute(), kdims=['width', 'height'])\n",
    "    hv_A_ma = hv.HoloMap(A_ma_dict, kdims=group_dim + ['session'])\n",
    "    hv_A_nm = hv.HoloMap(A_nm_dict, kdims=group_dim + ['session'])\n",
    "    hv_cent_ma = hv.Dataset(cur_cents_ma).to(hv.Points, kdims=['width', 'height'])\n",
    "    hv_cent_nm = hv.Dataset(cur_cents_nm).to(hv.Points, kdims=['width', 'height'])\n",
    "    hv_A = hv.HoloMap(dict(match=hv_A_ma, nonmatch=hv_A_nm), kdims=['matching']).collate()\n",
    "    hv_cent = hv.HoloMap(dict(match=hv_cent_ma, nonmatch=hv_cent_nm), kdims=['matching']).collate()\n",
    "    A_dict[cur_ss] = hv_A\n",
    "    cent_dict[cur_ss] = hv_cent\n",
    "hv_A = hv.HoloMap(A_dict, kdims=['session']).collate()\n",
    "hv_cent = hv.HoloMap(cent_dict, kdims=['session']).collate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=60\n",
    "from holoviews.operation.datashader import regrid\n",
    "(regrid(hv_A).opts(plot=dict(width=752, height=480), style=dict(cmap='Viridis'))).layout(['animal', 'matching']).cols(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
