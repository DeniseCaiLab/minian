{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minian_path = \".\"\n",
    "dpath = \"./demo_movies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.append(minian_path)\n",
    "import itertools as itt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import holoviews as hv\n",
    "import pandas as pd\n",
    "from holoviews.operation.datashader import datashade, regrid\n",
    "from minian.cross_registration import load_cnm_dataset, get_minian_list, estimate_shifts, apply_shifts, calculate_centroids, calculate_centroid_distance, calculate_mapping, group_by_session, resolve_mapping, fill_mapping\n",
    "from minian.utilities import resave_varr, update_meta\n",
    "from minian.visualization import AlignViewer\n",
    "from IPython.core.debugger import set_trace\n",
    "hv.notebook_extension('bokeh', width=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regi_list = []\n",
    "for anm_path in next(os.walk(dpath))[1]:\n",
    "    print(\"processing: {}\".format(anm_path))\n",
    "    anm_path = os.path.join(dpath, anm_path)\n",
    "    flist = get_minian_list(anm_path)\n",
    "    if not flist:\n",
    "        continue\n",
    "    shifts, corrs, temps = estimate_shifts(flist, ['first']*len(flist))\n",
    "    temps_sh = apply_shifts(temps, shifts)\n",
    "    temps = temps.astype(float)\n",
    "    temps_sh = temps_sh.astype(float)\n",
    "    cross_regi = xr.merge([shifts, corrs, temps, temps_sh])\n",
    "    regi_list.append(cross_regi)\n",
    "shiftds = xr.concat(regi_list, dim='animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output size=70\n",
    "%%opts Image [height=480, width=752]\n",
    "%%opts Layout [shared_datasource=True]\n",
    "alignviewer = AlignViewer(shiftds, sampling=5)\n",
    "alignviewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignviewer.shiftds.to_netcdf(os.path.join(dpath, \"shiftds.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sub_ds(ds):\n",
    "    return ds[['A', 'b']]\n",
    "\n",
    "for anm_path in next(os.walk(dpath))[1]:\n",
    "    try:\n",
    "        shifts = shiftds.sel(animal=anm_path)['shifts']\n",
    "    except KeyError:\n",
    "        print(\"no shift presented for animal {}\".format(anm_path))\n",
    "        continue\n",
    "    print(\"processing: {}\".format(anm_path))\n",
    "    anm_path = os.path.join(dpath, anm_path)\n",
    "    flist = get_minian_list(anm_path)\n",
    "    with xr.open_mfdataset(flist, concat_dim='session', preprocess=sub_ds) as cnmds:\n",
    "        print(\"loading spatial matrix\")\n",
    "        cnmds['A'].load()\n",
    "        cnmds['b'].load()\n",
    "        print(\"applying shift to spatial matrix\")\n",
    "        A_sh = apply_shifts(cnmds['A'], shifts)\n",
    "        b_sh = apply_shifts(cnmds['b'], shifts)\n",
    "        cnmds_sh = xr.merge([A_sh, b_sh])\n",
    "        print(\"saving results\")\n",
    "        cnmds_sh.to_netcdf(anm_path + os.sep + \"minian_anm_sh.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmds = xr.open_mfdataset(get_minian_list(dpath, pattern=r'^minian_anm_sh.nc$'), concat_dim='animal')\n",
    "shiftds = xr.open_dataset(os.path.join(dpath, \"shiftds.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_list = []\n",
    "for anm, temp_anm in shiftds['temps_shifted'].groupby('animal'):\n",
    "    cur_wnd = temp_anm.dropna('session', how='all').isnull().sum('session')\n",
    "    window_list.append(cur_wnd)\n",
    "windowds = xr.concat(window_list, dim='animal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=70\n",
    "%%opts Image [height=480, width=752] {+axiswise +framewise}\n",
    "hv_wnd = hv.Dataset(windowds, kdims=['animal', 'height', 'width'])\n",
    "hv_temps = hv.Dataset(shiftds['temps_shifted'], kdims=['animal', 'session', 'height', 'width'])\n",
    "regrid(hv_wnd.to(hv.Image, ['width', 'height'])) + regrid(hv_temps.to(hv.Image, ['width', 'height']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnmds['A_shifted'].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist = pd.read_pickle(\"/home/phild/Documents/sync/project/miniscope/data_temp/dist.pkl\")\n",
    "# dist_shifted_crop = pd.read_pickle(\"/home/phild/Documents/sync/project/miniscope/data_temp/dist_shifted_crop.pkl\")\n",
    "# dist_shifted_crop_dig = pd.read_pickle(\"/home/phild/Documents/sync/project/miniscope/data_temp/dist_shifted_crop_dig.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cents = calculate_centroids(cnmds, windowds==0)\n",
    "try:\n",
    "    cents = cents.drop('unit_labels', axis='columns')\n",
    "except KeyError:\n",
    "    pass\n",
    "cents.to_pickle(os.path.join(dpath, \"centroid.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cents = pd.read_pickle(os.path.join(dpath, \"centroid.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%output size=70\n",
    "%%opts Points [height=480, width=752] {+axiswise +framewise}\n",
    "cents_hv = hv.Dataset(cents, kdims=['height', 'width', 'unit_id', 'animal', 'session'])\n",
    "cents_hv.to(hv.Points, kdims=['width', 'height']).overlay('unit_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dist = calculate_centroid_distance(cents, cnmds, windowds==0, shift=False, hamming=False, corr=False)\n",
    "dist.to_pickle(os.path.join(dpath, \"distance.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ps = calculate_centroid_distance(cents, cnmds, windowds==0, shift=False, hamming=False, corr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hv_dist = datashade(hv.Points(dist['variable'], kdims=['coeff', 'distance'])).opts(plot={'width':500, 'height':500})\n",
    "hv_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.read_pickle(os.path.join(dpath, \"distance.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_ft = dist[dist['variable', 'distance'] < 5]\n",
    "dist_ft = group_by_session(dist_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = calculate_mapping(dist_ft)\n",
    "mappings_meta = resolve_mapping(mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings_meta_fill = fill_mapping(mappings_meta, cents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_list = []\n",
    "map_dict = {'1': 'A1', '2': 'B1', '3': 'BS', '4': 'A2', '5': 'B2', '6': 'C'}\n",
    "for (cur_anm, cur_map), cur_grp in mappings.groupby([mappings['meta', 'animal'], mappings['meta', 'group']]):\n",
    "    novlp = len(cur_grp)\n",
    "    nunit = [len(cents[(cents['animal'] == cur_anm) & (cents['session'] == ss)]) for ss in cur_map]\n",
    "    nA = nunit[0]\n",
    "    nB = nunit[1]\n",
    "    nSum = np.sum(nunit) - novlp\n",
    "    cur_map = tuple([map_dict[m] for m in cur_map])\n",
    "    cur_ovlp = pd.Series([cur_anm, cur_map, novlp/nSum, novlp/nA, novlp/nB, novlp/(nA*nB)], index=['animal', 'session', 'overlap', 'overlap-onA', 'overlap-onB', 'overlap-prod'])\n",
    "    overlap_list.append(cur_ovlp)\n",
    "overlaps = pd.concat(overlap_list, axis=1, ignore_index=True).T\n",
    "group_dict = dict(MS101='negative', MS104='negative', NS20='negative', NS22='negative', MS102='neutral', MS103='neutral', NS24='neutral')\n",
    "overlaps['group'] = overlaps['animal'].apply(lambda anm: group_dict[anm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_list = []\n",
    "map_dict = {'1': 'A1', '2': 'B1', '3': 'BS', '4': 'A2', '5': 'B2', '6': 'C'}\n",
    "for cur_anm, cur_grp in mappings_meta_fill.groupby(mappings_meta_fill['meta', 'animal']):\n",
    "    cur_ss = cur_grp['session'].dropna(axis='columns', how='all').columns\n",
    "    T = cur_grp['session'].dropna(axis='rows', how='all').shape[0]\n",
    "    for cur_map in itt.combinations(cur_ss, 2):\n",
    "        nint = cur_grp['session'][list(cur_map)].dropna(axis='rows', how='any').shape[0]\n",
    "        nuni = cur_grp['session'][list(cur_map)].dropna(axis='rows', how='all').shape[0]\n",
    "        nA = cur_grp['session'][cur_map[0]].dropna().size\n",
    "        nB = cur_grp['session'][cur_map[1]].dropna().size\n",
    "        cur_map = tuple([map_dict[m] for m in cur_map])\n",
    "        cur_ovlp = pd.Series([cur_anm, cur_map, nint/nuni, nint/nA, nint/nB, (nint*T)/(nA*nB)], index=['animal', 'session', 'overlap', 'overlap-onA', 'overlap-onB', 'overlap-prod'])\n",
    "        overlap_list.append(cur_ovlp)\n",
    "overlaps = pd.concat(overlap_list, axis=1, ignore_index=True).T\n",
    "group_dict = dict(MS101='negative', MS104='negative', NS20='negative', NS22='negative', MS102='neutral', MS103='neutral', NS24='neutral')\n",
    "overlaps['group'] = overlaps['animal'].apply(lambda anm: group_dict[anm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = overlaps.melt(id_vars=['animal', 'session', 'group'], var_name='overlap-type', value_name='overlap-value')\n",
    "overlaps['overlap-value'] = overlaps['overlap-value'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%opts BoxWhisker [width=1200, height=600, xrotation=90]\n",
    "overlap_hv = hv.Dataset(overlaps, kdims=['session', 'group', 'overlap-type'], vdims=['overlap-value'])\n",
    "overlap_hv.to(hv.BoxWhisker, kdims=['session', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Curve [width=1000, height=400, xrotation=90, tools=['hover']]\n",
    "overlap_hv_anm = hv.Dataset(overlaps, kdims=['animal', 'session', 'group', 'overlap-type'], vdims=['overlap-value'])\n",
    "overlap_hv_anm.to(hv.Curve, kdims=['session']).overlay('animal').layout('group').cols(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (minian)",
   "language": "python",
   "name": "minian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
